<pre>
 blog notes

-- what does it mean

what does trending mean; 
- the frequency of event in some time period outside normal
- c.f. outliers
- two images; one of smooth trend up, one with salt and pepper noise

-- the data

tweets about cheese for a period 20100125_2010022; 
436e3 entries / 27days
=> 16e3 a day

extract tweet text (these gzips are full of partial records thus thou shalt redirect json parsing to dev null)
(see run.sh)

first of all how many tweets per hour over this time? (678 entries)
<img src="tweets_over_day.60.nonaggregated.png"/>

what trending can we do on this timeseries?
how do we decide give a new value whether it respresents a trend?

TODO: REMOVE OUTLIERS!!!

1. mean and std dev over entire set

one simple way is compare the value to the historical mean. to make the comparison robust to 
normal flucuenation we compare to mean +/- 2x std dev

<img src="tweets_over_day.60.trending.png"/>
<img src="tweets_over_day.60.trending.zoom.png"/>

this gives us a model for the entire dataset; simplest

2. mean and std dev; compared to this time in previous days

makes each time series much smoother; but not as good at predicting the overall trend.
perhaps this needs to be more than 2x the std dev??
it's getting trends on the downways slope. this is ok (?)

<img src="tweets_over_day.60.periodic_trending.png"/>
<img src="tweets_over_day.60.periodic_trending.zoom.png"/>

how about with a sliding window, with as little as 10 previous numbers?
suprisingly, not too different. i guess this indicates that compared 
to same time of day the data is quite stable.

<img src="tweets_over_day.60.periodic_trending.sliding.png"/>
<img src="tweets_over_day.60.periodic_trending.sliding.zoom.png"/>

slot 9 - low point
slot 22 - high point

<img src="tweets_over_day.60.hi_low_trending.png"/>

this gives us model per 1hr chunk of the day; works well for values which are 'trending' even though the values are on the downturn

3. mean and std dev; per term

break down in terms in 1/2/3 grams

250e3 uniq 1grams; 64% of which are uniq
1.5e6 uniq 2grams; 75% of which are uniq
3.1e6 uniq 3grams; 86% of which are uniq


#4 22532 grilled cheese
<img src="tweets_over_day.60.grilledcheese.trending.png"/>
<!--<img src="tweets_over_day.60.grilledcheese.trending.zoom.png"/>-->

#5 18639 cream cheese
<img src="tweets_over_day.60.creamcheese.trending.png"/>
<!--<img src="tweets_over_day.60.creamcheese.trending.zoom.png"/>-->

#412 763 goats cheese
<img src="tweets_over_day.60.goatscheese.trending.png"/>
<!--<img src="tweets_over_day.60.goatscheese.trending.zoom.png"/>-->

#1483 288 apple juice
<img src="tweets_over_day.60.applejuice.trending.png"/>

#1434274 1 bus number

433534 -> 1589981 are all frequency 1

how to allow smaller frequency trends to trump trends of larger frequency items?
while not letting low values to blow everything up 
ie a 'freq' of 5 (from trend value of 2)
perhaps trend value = Math.log10(freq) * (freq/min_trend)

TODO

4. per term; mean and std dev comapred to this time previous days
------------------------------------

how can we notice when whether the direction has changed? is this stable?

how does this look per 15 min over the day?
img tweets_over_day.15.png

how does this look per hour over a week?
img tweets_over_week.1.png


how does this relate to the daily nature of the data? ie compare to same time a day ago?

how does this relate to the week nature of the data? ie compare to same time a week ago?

how do we do this per term?

how do we do this in pig?

# todo

approaches
- is there enough variance to bother comparing to this time yesterday / last week 
- mean of value +/- 2 stddevs...
 
simple version first
 - build model based on a range of data, say last 20 chunks
 - compare new chunk to mean +/- 2 std dev from chunks
 - how to calculate mean/stddev in pig?
 - do in ruby first to ensure we know what we're doing first...
 

